{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dipy.core.sphere import disperse_charges, HemiSphere, Sphere\n",
    "from dipy.direction import peak_directions\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere\n",
    "from dipy.sims.voxel import multi_tensor, multi_tensor_odf, single_tensor\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "import random\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:02.637575300Z",
     "start_time": "2023-12-17T20:05:02.616631800Z"
    }
   },
   "id": "5ae5dea14a77be17"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "thetas = list(np.load(\"synthetic_data/thetas.npy\"))\n",
    "phis = list(np.load(\"synthetic_data/phis.npy\"))\n",
    "\n",
    "hemisphere = HemiSphere(theta=thetas, phi=phis) # We already dispersed charges when building the hemisphere in dipy_test\n",
    "sphere = Sphere(xyz=np.vstack((hemisphere.vertices, -hemisphere.vertices)))\n",
    "\n",
    "\n",
    "def detect_peaks(F, relative_peak_threshold, min_separation_angle):\n",
    "    peak_format = np.zeros((len(F), 42))\n",
    "    max_peak_count = 0\n",
    "    for i, sample in enumerate(F):\n",
    "        # Duplicate the sample for both hemispheres\n",
    "        F_sphere = np.hstack((sample, sample)) / 2\n",
    "        # Find peak directions\n",
    "        directions, values, indices = peak_directions(F_sphere, sphere, relative_peak_threshold, min_separation_angle)\n",
    "        directions = sample[indices][:, np.newaxis] * directions # multiplying with fractions\n",
    "        directions_flattened = directions.flatten()\n",
    "        peak_format[i][0:len(directions_flattened)] = directions_flattened\n",
    "        if len(directions_flattened) / 3 > max_peak_count:\n",
    "            max_peak_count = len(directions_flattened) / 3\n",
    "    return peak_format, max_peak_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:03.110819600Z",
     "start_time": "2023-12-17T20:05:03.052465Z"
    }
   },
   "id": "7582179fd936fead"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "class MatrixFactorizationBatchNormalizationNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MatrixFactorizationBatchNormalizationNet, self).__init__()\n",
    "        # Define the network layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n",
    "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.softplus(self.fc4(x))  # Softplus activation for the output layer\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:05.236178500Z",
     "start_time": "2023-12-17T20:05:05.175342300Z"
    }
   },
   "id": "1fcc81078a1d85b"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 65)\n",
      "(500000, 180)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MatrixFactorizationNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MatrixFactorizationNet, self).__init__()\n",
    "        # Define the network layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.softplus(self.fc4(x))  # Softplus activation for the output layer\n",
    "        return x\n",
    "\n",
    "class MatrixDataset(Dataset):\n",
    "    def __init__(self, S, F):\n",
    "        self.S = S\n",
    "        self.F = F\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.S)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.S[idx], self.F[idx]\n",
    "    \n",
    "def apply_sparsity(F, sparsity_threshold=0.9):\n",
    "    max_value, _ = F.max(dim = 1, keepdim = True)\n",
    "    F[F < 0.1 * max_value] = 0\n",
    "    return F\n",
    "\n",
    "\n",
    "S = np.load(\"synthetic_data/uniform_5e5/S.npy\")\n",
    "F = np.load(\"synthetic_data/uniform_5e5/F.npy\")\n",
    "print(np.shape(S))\n",
    "print(np.shape(F))\n",
    "\n",
    "# Convert them to PyTorch tensors\n",
    "S = torch.from_numpy(S).float()\n",
    "# Separate into training and testing set\n",
    "split = 0.9\n",
    "num_entries = len(S)\n",
    "train_len = int(num_entries * split)\n",
    "\n",
    "S_train = S[:train_len]\n",
    "F_train = F[:train_len]\n",
    "\n",
    "S_test = S[train_len:]\n",
    "F_test = F[train_len:]\n",
    "batch_size = 1024\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dataset = MatrixDataset(S_train, F_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MatrixDataset(S_test, F_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "N_test, _ = np.shape(S_test)\n",
    "N, n_b = np.shape(S_train)\n",
    "_, n = np.shape(F_train)\n",
    "\n",
    "input_size = n_b\n",
    "output_size = n\n",
    "\n",
    "net = MatrixFactorizationBatchNormalizationNet(input_size, [512, 256, 128], output_size)\n",
    "net.load_state_dict(torch.load(\"trained_model/512_256_128_BN_uniform_diff_snrs_6e5_lr_0.001.pt\", map_location=torch.device('cpu')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:39.879877900Z",
     "start_time": "2023-12-17T20:05:37.832387600Z"
    }
   },
   "id": "ac70d5823dcf9c57"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "mask = nib.load('real_data/mask.nii').get_fdata().astype(bool)\n",
    "white_mask = nib.load('real_data/white_matter_mask.nii').get_fdata().astype(bool)\n",
    "\n",
    "hardi_snr10 = nib.load('real_data/DWIS_hardi-scheme_SNR-10.nii').get_fdata()\n",
    "hardi_snr20 = nib.load('real_data/DWIS_hardi-scheme_SNR-20.nii').get_fdata()\n",
    "hardi_snr30 = nib.load('real_data/DWIS_hardi-scheme_SNR-30.nii').get_fdata()\n",
    "\n",
    "hardi_snr10_masked = hardi_snr10[mask]\n",
    "hardi_snr20_masked = hardi_snr20[mask]\n",
    "hardi_snr30_masked = hardi_snr30[mask]\n",
    "hardi_snr10_masked *= (100/hardi_snr10_masked[0][0])\n",
    "hardi_snr20_masked *= (100/hardi_snr20_masked[0][0])\n",
    "hardi_snr30_masked *= (100/hardi_snr30_masked[0][0])\n",
    "\n",
    "hardi_snr10_white_masked = hardi_snr10[white_mask]\n",
    "hardi_snr20_white_masked = hardi_snr20[white_mask]\n",
    "hardi_snr30_white_masked = hardi_snr30[white_mask]\n",
    "hardi_snr10_white_masked *= (100/hardi_snr10_white_masked[0][0])\n",
    "hardi_snr20_white_masked *= (100/hardi_snr20_white_masked[0][0])\n",
    "hardi_snr30_white_masked *= (100/hardi_snr30_white_masked[0][0])\n",
    "\n",
    "gt_white_masked = pd.read_pickle(\"real_data/ground_truth_peaks_white_masked.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:41.608801400Z",
     "start_time": "2023-12-17T20:05:41.149030700Z"
    }
   },
   "id": "e766195dd6b51b40"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "test_set_hardi = torch.from_numpy(hardi_snr30_white_masked).float()\n",
    "F_test_set_hardi = torch.from_numpy(np.zeros(hardi_snr30_white_masked.shape[0])).float()\n",
    "test_dataset_hardi = MatrixDataset(test_set_hardi, F_test_set_hardi)\n",
    "test_loader_hardi = DataLoader(test_dataset_hardi, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:41.797297100Z",
     "start_time": "2023-12-17T20:05:41.735461700Z"
    }
   },
   "id": "eafc512019f8e595"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    F_pred_matrix_normalized_list = []\n",
    "\n",
    "    for S_batch, F_batch in test_loader_hardi:\n",
    "        S_batch_flattened = S_batch.to_dense().view(S_batch.size(0), -1)\n",
    "\n",
    "        F_batch_pred = net(S_batch_flattened)\n",
    "        F_batch_pred = apply_sparsity(F_batch_pred)\n",
    "        F_batch_pred_normalized = F_batch_pred / (F_batch_pred.sum(dim=1, keepdim=True) + 1e8)\n",
    "\n",
    "        #loss = criterion(F_batch_pred_normalized, F_batch)\n",
    "\n",
    "        #total_loss += loss.item()\n",
    "        F_pred_matrix_normalized_list.append(F_batch_pred_normalized)\n",
    "\n",
    "    # Calculate the average loss over all test samples\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(\"Average Test Loss:\", avg_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:43.019778300Z",
     "start_time": "2023-12-17T20:05:42.583120500Z"
    }
   },
   "id": "26ae2c6afe721f03"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "F_pred_np = np.concatenate([tensor.cpu().numpy().flatten() for tensor in F_pred_matrix_normalized_list])\n",
    "F_pred_np = F_pred_np.reshape((-1,180)).astype(np.double)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:44.003533Z",
     "start_time": "2023-12-17T20:05:43.931670Z"
    }
   },
   "id": "45070b069920ae3b"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "relative_peak_threshold = 0.1\n",
    "min_separation_angle = 25\n",
    "\n",
    "peak_format, peak_count = detect_peaks(F_pred_np, relative_peak_threshold, min_separation_angle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:05:47.630804300Z",
     "start_time": "2023-12-17T20:05:45.345288400Z"
    }
   },
   "id": "c237a066b735020a"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "pd.to_pickle(peak_format, \"trained_model/512_256_128_BN_uniform_diff_snrs_6e5_lr_0.001.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:06:03.487292900Z",
     "start_time": "2023-12-17T20:06:03.433176900Z"
    }
   },
   "id": "b998d92fef742ec1"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "angle_pairs = pd.read_pickle(\"synthetic_data/angle_pairs.pkl\")\n",
    "evals = np.tile([0.0017, 0.0002, 0.0002], (len(angle_pairs), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:06:15.182298300Z",
     "start_time": "2023-12-17T20:06:15.154374200Z"
    }
   },
   "id": "97386f0621e95c1b"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def cartesian_to_spherical(x, y, z):\n",
    "    # Calculate phi (azimuthal angle)\n",
    "    phi = math.atan2(y, x)\n",
    "    \n",
    "    # Calculate theta (polar angle)\n",
    "    r_xy = math.sqrt(x**2 + y**2)\n",
    "    theta = math.atan2(r_xy, z)\n",
    "    \n",
    "    # Convert angles to degrees\n",
    "    phi_deg = math.degrees(phi)\n",
    "    theta_deg = math.degrees(theta)\n",
    "    \n",
    "    return phi_deg,theta_deg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:06:15.830172400Z",
     "start_time": "2023-12-17T20:06:15.800251700Z"
    }
   },
   "id": "87cd998cab19c376"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def angles_fractions(gt):\n",
    "    angles = []\n",
    "    fractions = []\n",
    "    for i in range(len(gt)//3):\n",
    "        if gt[3*i] != 0.0:\n",
    "            phi, theta = cartesian_to_spherical(gt[3*i], gt[3*i+1], gt[3*i+2])\n",
    "            angles.append((theta, phi))\n",
    "            fractions.append(gt[3*i]**2 + gt[3*i+1]**2 + gt[3*i+2]**2)\n",
    "    fractions = fractions / sum(fractions)\n",
    "    return angles, fractions\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:06:16.762925700Z",
     "start_time": "2023-12-17T20:06:16.736996Z"
    }
   },
   "id": "19bce6250d9ea9b2"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "sphere2 = get_sphere('repulsion724').subdivide(1)\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "for i in range(15):\n",
    "    \n",
    "    random_number = random.randint(0, len(F_pred_np))\n",
    "    _, peak_count = detect_peaks(F_pred_np[random_number].reshape(1,-1), 0.5, 25)\n",
    "    gt_peak_count = np.count_nonzero(gt_white_masked[random_number]) / 3\n",
    "    odf = multi_tensor_odf(sphere2.vertices, evals, angles=angle_pairs,\n",
    "                              fractions=F_pred_np[random_number])\n",
    "    \n",
    "    gt_angles, gt_fractions = angles_fractions(gt_white_masked[random_number])\n",
    "    odf_gt = multi_tensor_odf(sphere2.vertices, evals, angles=gt_angles,\n",
    "                              fractions=gt_fractions)\n",
    "    \n",
    "    from dipy.viz import window, actor\n",
    "    \n",
    "    # Enables/disables interactive visualization\n",
    "    interactive = False\n",
    "    \n",
    "    \n",
    "    scene = window.Scene()\n",
    "    \n",
    "    odfs = np.vstack((odf, odf_gt))[:, None, None]\n",
    "    odf_actor = actor.odf_slicer(odfs, sphere=sphere2, scale=0.5, colormap='plasma')\n",
    "    \n",
    "    odf_actor.display(y=0)\n",
    "    odf_actor.RotateX(90)\n",
    "    scene.add(odf_actor)\n",
    "    window.record(scene, out_path='trained_model/hardi_results/threshold_3_res_' + str(random_number) + 'peak_count_' + str(peak_count) + '_gt_peak_count_' + str(gt_peak_count) + '.png', size=(300, 300))\n",
    "    if interactive:\n",
    "        window.show(scene)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:07:16.955567Z",
     "start_time": "2023-12-17T20:06:48.667724700Z"
    }
   },
   "id": "fe3db7f6a18c1840"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gt_angles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db71d937f6cc8718"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_number"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3076d48a19fa229"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hardi_snr30_white_masked[849]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "544ca971821c0a22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('real_data/hardi-scheme.bvec.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "real_bvecs = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    real_bvecs.append([float(value) for value in values])\n",
    "real_bvecs = np.array(real_bvecs).T\n",
    "\n",
    "\n",
    "with open('real_data/hardi-scheme.bval.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "real_bvals = []\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    real_bvals.append([float(value) for value in values])\n",
    "\n",
    "real_bvals = np.array(real_bvals).reshape(-1)\n",
    "\n",
    "gtab = gradient_table(real_bvals, real_bvecs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "894d2f4835bf9485"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d_parallel = 0.0015\n",
    "d_perp = 0.00039\n",
    "eigenvals = [d_parallel, d_perp, d_perp]\n",
    "a = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=30)[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b564f682833169b7"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[105.80883414,  18.47758824,  15.42564515, ...,  11.44683225,\n         25.84922221,  20.60763734],\n       [ 99.58721804,  19.13866153,  20.49738568, ...,  19.29782281,\n         10.33689156,  16.57899893],\n       [100.        ,   6.74715108,  15.97139409, ...,  19.96619745,\n         15.99120786,  25.95446839],\n       ...,\n       [110.1815024 ,   6.80477209,   6.23242756, ...,  13.85581028,\n         21.89885241,  28.2759651 ],\n       [102.18475096,  16.69135328,   7.81423082, ...,   2.66162189,\n         11.14373645,   7.7727093 ],\n       [ 99.79075947,  24.29025214,  19.6397756 , ...,  29.3103679 ,\n         19.1689361 ,  27.5113017 ]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(a)\n",
    "plt.plot(hardi_snr30_white_masked[849])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T16:04:45.005506800Z",
     "start_time": "2023-12-17T16:04:44.821991500Z"
    }
   },
   "id": "966e3574dcfc2282"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "a_20 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=20)[0]\n",
    "plt.plot(a_20)\n",
    "plt.plot(hardi_snr20_white_masked[849])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T17:49:29.539528200Z",
     "start_time": "2023-12-17T17:49:29.117808800Z"
    }
   },
   "id": "389037b3b5a1ae42"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[105.80883414,  18.47758824,  15.42564515, ...,  11.44683225,\n         25.84922221,  20.60763734],\n       [ 99.58721804,  19.13866153,  20.49738568, ...,  19.29782281,\n         10.33689156,  16.57899893],\n       [100.        ,   6.74715108,  15.97139409, ...,  19.96619745,\n         15.99120786,  25.95446839],\n       ...,\n       [110.1815024 ,   6.80477209,   6.23242756, ...,  13.85581028,\n         21.89885241,  28.2759651 ],\n       [102.18475096,  16.69135328,   7.81423082, ...,   2.66162189,\n         11.14373645,   7.7727093 ],\n       [ 99.79075947,  24.29025214,  19.6397756 , ...,  29.3103679 ,\n         19.1689361 ,  27.5113017 ]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_10 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=10)[0]\n",
    "plt.plot(a_10)\n",
    "plt.plot(hardi_snr10_white_masked[849])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T17:49:30.697070200Z",
     "start_time": "2023-12-17T17:49:30.625451700Z"
    }
   },
   "id": "3edc95cc4c4d0fd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a_10 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=10)[0]\n",
    "plt.plot(a_10)\n",
    "a_15 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=15)[0]\n",
    "plt.plot(a_10)\n",
    "a_20 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=20)[0]\n",
    "plt.plot(a_10)\n",
    "a_25 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=25)[0]\n",
    "plt.plot(a_10)\n",
    "a_30 = multi_tensor(gtab, mevals = [eigenvals], S0=100, angles=gt_angles, fractions=[100], snr=30)[0]\n",
    "plt.plot(a_10)\n",
    "\n",
    "plt.plot(a_10)\n",
    "plt.plot(a_15)\n",
    "plt.plot(a_20)\n",
    "plt.plot(a_25)\n",
    "plt.plot(a_30)\n",
    "plt.plot(hardi_snr30_white_masked[849], linewidth = 3.0, color = 'red')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f414aca7612f56"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "S = np.load(\"synthetic_data/tugbanindahiyanefikri_custom/S.npy\")\n",
    "F = np.load(\"synthetic_data/tugbanindahiyanefikri_custom/F.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:47:32.610519Z",
     "start_time": "2023-12-17T15:47:30.461853300Z"
    }
   },
   "id": "2f52761dd2a08a94"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Combine into pairs\n",
    "combined_data = list(zip(S, F))\n",
    "\n",
    "# Shuffle the pairs\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Unzip back into separate arrays\n",
    "S, F = zip(*combined_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:47:35.653417500Z",
     "start_time": "2023-12-17T15:47:33.173027700Z"
    }
   },
   "id": "2041f2dccf7c38fa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "np.save(\"synthetic_data/tugbanindahiyanefikri_custom/S.npy\", S)\n",
    "np.save(\"synthetic_data/tugbanindahiyanefikri_custom/F.npy\", F)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:47:49.188638800Z",
     "start_time": "2023-12-17T15:47:42.191662100Z"
    }
   },
   "id": "9484f12aa66247a0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[105.80883414,  18.47758824,  15.42564515, ...,  11.44683225,\n         25.84922221,  20.60763734],\n       [ 99.58721804,  19.13866153,  20.49738568, ...,  19.29782281,\n         10.33689156,  16.57899893],\n       [100.        ,   6.74715108,  15.97139409, ...,  19.96619745,\n         15.99120786,  25.95446839],\n       ...,\n       [110.1815024 ,   6.80477209,   6.23242756, ...,  13.85581028,\n         21.89885241,  28.2759651 ],\n       [102.18475096,  16.69135328,   7.81423082, ...,   2.66162189,\n         11.14373645,   7.7727093 ],\n       [ 99.79075947,  24.29025214,  19.6397756 , ...,  29.3103679 ,\n         19.1689361 ,  27.5113017 ]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(S)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:47:51.856127300Z",
     "start_time": "2023-12-17T15:47:50.777569Z"
    }
   },
   "id": "77cf67570536d37"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(F)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:47:53.674254900Z",
     "start_time": "2023-12-17T15:47:51.847118100Z"
    }
   },
   "id": "3b6b364823f9f1c"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "gt_peaks = pd.read_pickle(\"real_data/ground_truth_peaks_white_masked.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:24:18.968003900Z",
     "start_time": "2023-12-17T20:24:18.940856300Z"
    }
   },
   "id": "ba20de317af43661"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "# Calculate the number of columns to add on each side\n",
    "columns_to_add = 42 - gt_peaks.shape[1]\n",
    "\n",
    "# Pad the matrix with zeros\n",
    "padded_matrix = np.pad(gt_peaks, ((0, 0), (0, columns_to_add)), mode='constant', constant_values=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:24:25.945000600Z",
     "start_time": "2023-12-17T20:24:25.893762800Z"
    }
   },
   "id": "a1b0d3d8e4b983d0"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:24:35.883607900Z",
     "start_time": "2023-12-17T20:24:35.781877Z"
    }
   },
   "id": "f6dbd81ba4e8a89"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "pd.to_pickle(padded_matrix, \"real_data/ground_truth_peaks_padded.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:24:56.472936300Z",
     "start_time": "2023-12-17T20:24:56.418797400Z"
    }
   },
   "id": "1c2405504fe8653e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d239538ade23193b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
