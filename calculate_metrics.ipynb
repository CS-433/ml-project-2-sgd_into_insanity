{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dipy.core.sphere import disperse_charges, HemiSphere, Sphere\n",
    "from dipy.direction import peak_directions\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere\n",
    "from dipy.sims.voxel import multi_tensor, multi_tensor_odf, single_tensor\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "import random\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:43:48.223337500Z",
     "start_time": "2023-12-15T22:43:48.196410500Z"
    }
   },
   "id": "5ae5dea14a77be17"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "thetas = list(np.load(\"synthetic_data/thetas.npy\"))\n",
    "phis = list(np.load(\"synthetic_data/phis.npy\"))\n",
    "\n",
    "hemisphere = HemiSphere(theta=thetas, phi=phis) # We already dispersed charges when building the hemisphere in dipy_test\n",
    "sphere = Sphere(xyz=np.vstack((hemisphere.vertices, -hemisphere.vertices)))\n",
    "\n",
    "\n",
    "def detect_peaks(F, relative_peak_threshold, min_separation_angle):\n",
    "    peak_format = np.zeros((len(F), 42))\n",
    "    max_peak_count = 0\n",
    "    for i, sample in enumerate(F):\n",
    "        # Duplicate the sample for both hemispheres\n",
    "        F_sphere = np.hstack((sample, sample)) / 2\n",
    "        # Find peak directions\n",
    "        directions, values, indices = peak_directions(F_sphere, sphere, relative_peak_threshold, min_separation_angle)\n",
    "        directions = sample[indices][:, np.newaxis] * directions # multiplying with fractions\n",
    "        directions_flattened = directions.flatten()\n",
    "        peak_format[i][0:len(directions_flattened)] = directions_flattened\n",
    "        if len(directions_flattened) / 3 > max_peak_count:\n",
    "            max_peak_count = len(directions_flattened) / 3\n",
    "    return peak_format, max_peak_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:43:48.467793800Z",
     "start_time": "2023-12-15T22:43:48.440446900Z"
    }
   },
   "id": "7582179fd936fead"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 65)\n",
      "(500000, 180)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MatrixFactorizationNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MatrixFactorizationNet, self).__init__()\n",
    "        # Define the network layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.softplus(self.fc4(x))  # Softplus activation for the output layer\n",
    "        return x\n",
    "\n",
    "class MatrixDataset(Dataset):\n",
    "    def __init__(self, S, F):\n",
    "        self.S = S\n",
    "        self.F = F\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.S)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.S[idx], self.F[idx]\n",
    "    \n",
    "def apply_sparsity(F, sparsity_threshold=0.9):\n",
    "    max_value, _ = F.max(dim = 1, keepdim = True)\n",
    "    F[F < 0.1 * max_value] = 0\n",
    "    return F\n",
    "\n",
    "\n",
    "S = np.load(\"synthetic_data/S.npy\")\n",
    "F = np.load(\"synthetic_data/F.npy\")\n",
    "print(np.shape(S))\n",
    "print(np.shape(F))\n",
    "\n",
    "# Convert them to PyTorch tensors\n",
    "S = torch.from_numpy(S).float()\n",
    "# Separate into training and testing set\n",
    "split = 0.9\n",
    "num_entries = len(S)\n",
    "train_len = int(num_entries * split)\n",
    "\n",
    "S_train = S[:train_len]\n",
    "F_train = F[:train_len]\n",
    "\n",
    "S_test = S[train_len:]\n",
    "F_test = F[train_len:]\n",
    "batch_size = 1024\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dataset = MatrixDataset(S_train, F_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MatrixDataset(S_test, F_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "N_test, _ = np.shape(S_test)\n",
    "N, n_b = np.shape(S_train)\n",
    "_, n = np.shape(F_train)\n",
    "\n",
    "input_size = n_b\n",
    "output_size = n\n",
    "\n",
    "net = MatrixFactorizationNet(input_size, [512, 256, 128], output_size)\n",
    "net.load_state_dict(torch.load(\"trained_model/model_15_12_custom_dist_1e5.pt\", map_location=torch.device('cpu')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:12.662049400Z",
     "start_time": "2023-12-15T22:44:11.690365500Z"
    }
   },
   "id": "ac70d5823dcf9c57"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "mask = nib.load('real_data/mask.nii').get_fdata().astype(bool)\n",
    "white_mask = nib.load('real_data/white_matter_mask.nii').get_fdata().astype(bool)\n",
    "\n",
    "hardi_snr10 = nib.load('real_data/DWIS_hardi-scheme_SNR-10.nii').get_fdata()\n",
    "hardi_snr20 = nib.load('real_data/DWIS_hardi-scheme_SNR-20.nii').get_fdata()\n",
    "hardi_snr30 = nib.load('real_data/DWIS_hardi-scheme_SNR-30.nii').get_fdata()\n",
    "\n",
    "hardi_snr10_masked = hardi_snr10[mask]\n",
    "hardi_snr20_masked = hardi_snr20[mask]\n",
    "hardi_snr30_masked = hardi_snr30[mask]\n",
    "hardi_snr10_masked *= (100/hardi_snr10_masked[0][0])\n",
    "hardi_snr20_masked *= (100/hardi_snr20_masked[0][0])\n",
    "hardi_snr30_masked *= (100/hardi_snr30_masked[0][0])\n",
    "\n",
    "hardi_snr10_white_masked = hardi_snr10[white_mask]\n",
    "hardi_snr20_white_masked = hardi_snr20[white_mask]\n",
    "hardi_snr30_white_masked = hardi_snr30[white_mask]\n",
    "hardi_snr10_white_masked *= (100/hardi_snr10_white_masked[0][0])\n",
    "hardi_snr20_white_masked *= (100/hardi_snr20_white_masked[0][0])\n",
    "hardi_snr30_white_masked *= (100/hardi_snr30_white_masked[0][0])\n",
    "\n",
    "gt_white_masked = pd.read_pickle(\"real_data/ground_truth_peaks_white_masked.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:24.625042100Z",
     "start_time": "2023-12-15T22:44:24.217132200Z"
    }
   },
   "id": "e766195dd6b51b40"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "test_set_hardi = torch.from_numpy(hardi_snr30_white_masked).float()\n",
    "F_test_set_hardi = torch.from_numpy(np.zeros(hardi_snr30_white_masked.shape[0])).float()\n",
    "test_dataset_hardi = MatrixDataset(test_set_hardi, F_test_set_hardi)\n",
    "test_loader_hardi = DataLoader(test_dataset_hardi, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:24.895012300Z",
     "start_time": "2023-12-15T22:44:24.877061500Z"
    }
   },
   "id": "eafc512019f8e595"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    F_pred_matrix_normalized_list = []\n",
    "\n",
    "    for S_batch, F_batch in test_loader_hardi:\n",
    "        S_batch_flattened = S_batch.to_dense().view(S_batch.size(0), -1)\n",
    "\n",
    "        F_batch_pred = net(S_batch_flattened)\n",
    "        F_batch_pred = apply_sparsity(F_batch_pred)\n",
    "        F_batch_pred_normalized = F_batch_pred / F_batch_pred.sum(dim=1, keepdim=True)\n",
    "\n",
    "        #loss = criterion(F_batch_pred_normalized, F_batch)\n",
    "\n",
    "        #total_loss += loss.item()\n",
    "        F_pred_matrix_normalized_list.append(F_batch_pred_normalized)\n",
    "\n",
    "    # Calculate the average loss over all test samples\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(\"Average Test Loss:\", avg_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:26.387293200Z",
     "start_time": "2023-12-15T22:44:25.470744900Z"
    }
   },
   "id": "26ae2c6afe721f03"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "F_pred_np = np.concatenate([tensor.cpu().numpy().flatten() for tensor in F_pred_matrix_normalized_list])\n",
    "F_pred_np = F_pred_np.reshape((-1,180)).astype(np.double)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:26.455111300Z",
     "start_time": "2023-12-15T22:44:26.383305Z"
    }
   },
   "id": "45070b069920ae3b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.04457189 0.08100978\n",
      " 0.25074464 0.12433697 0.1849499  0.31438673]\n",
      "[ 61  60  64  62  47  57 170  69 102 121]\n",
      "[0. 0. 1.]\n",
      "[ 60 179 132]\n"
     ]
    }
   ],
   "source": [
    "indices_top10 = np.argpartition(F_pred_np[0], -10)[-10:]\n",
    "\n",
    "# Get the top 10 largest elements\n",
    "print(F_pred_np[0][indices_top10])\n",
    "print(indices_top10)\n",
    "\n",
    "indices_top3_true = np.argpartition(F_test[0], -3)[-3:]\n",
    "# Get the top 3 largest elements\n",
    "print(F_test[0][indices_top3_true])\n",
    "print(indices_top3_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T19:36:06.258841400Z",
     "start_time": "2023-12-15T19:36:06.199999900Z"
    }
   },
   "id": "aa803815b91516db"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Values in edges must be < len(odf)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m relative_peak_threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m\n\u001B[0;32m      2\u001B[0m min_separation_angle \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m25\u001B[39m\n\u001B[1;32m----> 4\u001B[0m peak_format, peak_count \u001B[38;5;241m=\u001B[39m \u001B[43mdetect_peaks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mF_pred_np\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrelative_peak_threshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_separation_angle\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[42], line 16\u001B[0m, in \u001B[0;36mdetect_peaks\u001B[1;34m(F, relative_peak_threshold, min_separation_angle)\u001B[0m\n\u001B[0;32m     13\u001B[0m F_sphere \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack((sample, sample)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Find peak directions\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m directions, values, indices \u001B[38;5;241m=\u001B[39m \u001B[43mpeak_directions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mF_sphere\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msphere\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrelative_peak_threshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_separation_angle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m directions \u001B[38;5;241m=\u001B[39m sample[indices][:, np\u001B[38;5;241m.\u001B[39mnewaxis] \u001B[38;5;241m*\u001B[39m directions \u001B[38;5;66;03m# multiplying with fractions\u001B[39;00m\n\u001B[0;32m     18\u001B[0m directions_flattened \u001B[38;5;241m=\u001B[39m directions\u001B[38;5;241m.\u001B[39mflatten()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\dipy\\direction\\peaks.py:132\u001B[0m, in \u001B[0;36mpeak_directions\u001B[1;34m(odf, sphere, relative_peak_threshold, min_separation_angle, is_symmetric)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpeak_directions\u001B[39m(odf, sphere, relative_peak_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.5\u001B[39m,\n\u001B[0;32m     93\u001B[0m                     min_separation_angle\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, is_symmetric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     94\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the directions of odf peaks.\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \n\u001B[0;32m     96\u001B[0m \u001B[38;5;124;03m    Peaks are defined as points on the odf that are greater than at least one\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    130\u001B[0m \n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 132\u001B[0m     values, indices \u001B[38;5;241m=\u001B[39m \u001B[43mlocal_maxima\u001B[49m\u001B[43m(\u001B[49m\u001B[43modf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msphere\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medges\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;66;03m# If there is only one peak return\u001B[39;00m\n\u001B[0;32m    135\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(values)\n",
      "File \u001B[1;32mdipy\\reconst\\recspeed.pyx:247\u001B[0m, in \u001B[0;36mdipy.reconst.recspeed.local_maxima\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: Values in edges must be < len(odf)"
     ]
    }
   ],
   "source": [
    "relative_peak_threshold = 0.1\n",
    "min_separation_angle = 25\n",
    "\n",
    "peak_format, peak_count = detect_peaks(F_pred_np[1].reshape(1,-1), relative_peak_threshold, min_separation_angle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T19:52:28.719379300Z",
     "start_time": "2023-12-15T19:52:28.655578100Z"
    }
   },
   "id": "c237a066b735020a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.30097467, 0.05795585, 0.06995984, ..., 0.        , 0.        ,\n        0.        ],\n       [0.22633837, 0.22264666, 0.24471267, ..., 0.        , 0.        ,\n        0.        ],\n       [0.01152044, 0.02600314, 0.20201097, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.2099885 , 0.20656347, 0.22703551, ..., 0.        , 0.        ,\n        0.        ],\n       [0.17811752, 0.17521232, 0.19257722, ..., 0.        , 0.        ,\n        0.        ],\n       [0.11972951, 0.11777665, 0.12944923, ..., 0.        , 0.        ,\n        0.        ]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T19:36:38.260199900Z",
     "start_time": "2023-12-15T19:36:38.223163300Z"
    }
   },
   "id": "c6a0438cbf259004"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "11.0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T19:36:39.212937800Z",
     "start_time": "2023-12-15T19:36:39.176036500Z"
    }
   },
   "id": "3c1cd6245a6e7fb7"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pd.to_pickle(peak_format, \"trained.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:47:12.378895500Z",
     "start_time": "2023-12-13T22:47:12.307469300Z"
    }
   },
   "id": "d99c9599ff7193f4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "a = pd.read_pickle(\"synthetic_data/peaks_synthetic_formatted.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:49.784648800Z",
     "start_time": "2023-12-13T22:43:49.754338600Z"
    }
   },
   "id": "a24c0f805f8b815e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cutted_gt = a[train_len:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:51.059249700Z",
     "start_time": "2023-12-13T22:43:51.019849900Z"
    }
   },
   "id": "a8d507c1d8714601"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "pd.to_pickle(cutted_gt, 'gt_peaks_val_set.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:51.501234400Z",
     "start_time": "2023-12-13T22:43:51.454185500Z"
    }
   },
   "id": "36ee05b286e96189"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "angle_pairs = pd.read_pickle(\"synthetic_data/angle_pairs.pkl\")\n",
    "evals = np.tile([0.0017, 0.0002, 0.0002], (len(angle_pairs), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:36.942864Z",
     "start_time": "2023-12-15T22:44:36.923916500Z"
    }
   },
   "id": "97386f0621e95c1b"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def cartesian_to_spherical(x, y, z):\n",
    "    # Calculate phi (azimuthal angle)\n",
    "    phi = math.atan2(y, x)\n",
    "    \n",
    "    # Calculate theta (polar angle)\n",
    "    r_xy = math.sqrt(x**2 + y**2)\n",
    "    theta = math.atan2(r_xy, z)\n",
    "    \n",
    "    # Convert angles to degrees\n",
    "    phi_deg = math.degrees(phi)\n",
    "    theta_deg = math.degrees(theta)\n",
    "    \n",
    "    return phi_deg,theta_deg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:37.239595Z",
     "start_time": "2023-12-15T22:44:37.209685800Z"
    }
   },
   "id": "87cd998cab19c376"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def angles_fractions(gt):\n",
    "    angles = []\n",
    "    fractions = []\n",
    "    for i in range(len(gt)//3):\n",
    "        if gt[3*i] != 0.0:\n",
    "            phi, theta = cartesian_to_spherical(gt[3*i], gt[3*i+1], gt[3*i+2])\n",
    "            angles.append((theta, phi))\n",
    "            fractions.append(gt[3*i]**2 + gt[3*i+1]**2 + gt[3*i+2]**2)\n",
    "    fractions = fractions / sum(fractions)\n",
    "    return angles, fractions\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:44:40.825681200Z",
     "start_time": "2023-12-15T22:44:40.794771200Z"
    }
   },
   "id": "19bce6250d9ea9b2"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "sphere2 = get_sphere('repulsion724').subdivide(1)\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "for i in range(15):\n",
    "    \n",
    "    random_number = random.randint(0, len(F_pred_np))\n",
    "    _, peak_count = detect_peaks(F_pred_np[random_number].reshape(1,-1), 0.5, 25)\n",
    "    gt_peak_count = np.count_nonzero(gt_white_masked[random_number]) / 3\n",
    "    odf = multi_tensor_odf(sphere2.vertices, evals, angles=angle_pairs,\n",
    "                              fractions=F_pred_np[random_number])\n",
    "    \n",
    "    gt_angles, gt_fractions = angles_fractions(gt_white_masked[random_number])\n",
    "    odf_gt = multi_tensor_odf(sphere2.vertices, evals, angles=gt_angles,\n",
    "                              fractions=gt_fractions)\n",
    "    \n",
    "    from dipy.viz import window, actor\n",
    "    \n",
    "    # Enables/disables interactive visualization\n",
    "    interactive = False\n",
    "    \n",
    "    \n",
    "    scene = window.Scene()\n",
    "    \n",
    "    odfs = np.vstack((odf, odf_gt))[:, None, None]\n",
    "    odf_actor = actor.odf_slicer(odfs, sphere=sphere2, scale=0.5, colormap='plasma')\n",
    "    \n",
    "    odf_actor.display(y=0)\n",
    "    odf_actor.RotateX(90)\n",
    "    scene.add(odf_actor)\n",
    "    window.record(scene, out_path='trained_model/hardi_results/threshold_3_res_' + str(random_number) + 'peak_count_' + str(peak_count) + '_gt_peak_count_' + str(gt_peak_count) + '.png', size=(300, 300))\n",
    "    if interactive:\n",
    "        window.show(scene)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:45:51.015692Z",
     "start_time": "2023-12-15T22:45:30.187141900Z"
    }
   },
   "id": "fe3db7f6a18c1840"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bae1af823ce9916d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
