{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dipy.core.sphere import disperse_charges, HemiSphere, Sphere\n",
    "from dipy.direction import peak_directions\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere\n",
    "from dipy.sims.voxel import multi_tensor, multi_tensor_odf, single_tensor\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import nibabel as nib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:14.044168300Z",
     "start_time": "2023-12-13T22:43:04.743025500Z"
    }
   },
   "id": "5ae5dea14a77be17"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "thetas = list(np.load(\"synthetic_data/thetas.npy\"))\n",
    "phis = list(np.load(\"synthetic_data/phis.npy\"))\n",
    "\n",
    "hemisphere = HemiSphere(theta=thetas, phi=phis) # We already dispersed charges when building the hemisphere in dipy_test\n",
    "sphere = Sphere(xyz=np.vstack((hemisphere.vertices, -hemisphere.vertices)))\n",
    "\n",
    "\n",
    "def detect_peaks(F, relative_peak_threshold, min_separation_angle):\n",
    "    peak_format = np.zeros((len(F), 42))\n",
    "    max_peak_count = 0\n",
    "    for i, sample in enumerate(F):\n",
    "        # Duplicate the sample for both hemispheres\n",
    "        F_sphere = np.hstack((sample, sample)) / 2\n",
    "\n",
    "        # Find peak directions\n",
    "        directions, values, indices = peak_directions(F_sphere, sphere, relative_peak_threshold, min_separation_angle)\n",
    "        directions = sample[indices][:, np.newaxis] * directions # multiplying with fractions\n",
    "        directions_flattened = directions.flatten()\n",
    "        peak_format[i][0:len(directions_flattened)] = directions_flattened\n",
    "        if len(directions_flattened) / 3 > max_peak_count:\n",
    "            max_peak_count = len(directions_flattened) / 3\n",
    "    return peak_format, max_peak_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:47:04.968915300Z",
     "start_time": "2023-12-13T22:47:04.929616Z"
    }
   },
   "id": "7582179fd936fead"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 65)\n",
      "(100000, 180)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MatrixFactorizationNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MatrixFactorizationNet, self).__init__()\n",
    "        # Define the network layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.softplus(self.fc4(x))  # Softplus activation for the output layer\n",
    "        return x\n",
    "\n",
    "class MatrixDataset(Dataset):\n",
    "    def __init__(self, S, F):\n",
    "        self.S = S\n",
    "        self.F = F\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.S)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.S[idx], self.F[idx]\n",
    "    \n",
    "def apply_sparsity(F, sparsity_threshold=0.9):\n",
    "    max_value, _ = F.max(dim = 1, keepdim = True)\n",
    "    F[F < 0.1 * max_value] = 0\n",
    "    return F\n",
    "\n",
    "\n",
    "S = np.load(\"synthetic_data/S.npy\")\n",
    "F = np.load(\"synthetic_data/F.npy\")\n",
    "print(np.shape(S))\n",
    "print(np.shape(F))\n",
    "\n",
    "# Convert them to PyTorch tensors\n",
    "S = torch.from_numpy(S).float()\n",
    "# Separate into training and testing set\n",
    "split = 0.9\n",
    "num_entries = len(S)\n",
    "train_len = int(num_entries * split)\n",
    "\n",
    "S_train = S[:train_len]\n",
    "F_train = F[:train_len]\n",
    "\n",
    "S_test = S[train_len:]\n",
    "F_test = F[train_len:]\n",
    "batch_size = 1024\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_dataset = MatrixDataset(S_train, F_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MatrixDataset(S_test, F_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "N_test, _ = np.shape(S_test)\n",
    "N, n_b = np.shape(S_train)\n",
    "_, n = np.shape(F_train)\n",
    "\n",
    "input_size = n_b\n",
    "output_size = n\n",
    "\n",
    "net = MatrixFactorizationNet(input_size, [512, 256, 128], output_size)\n",
    "net.load_state_dict(torch.load(\"trained_model/model_13_12_no_sparsity.pt\", map_location=torch.device('cpu')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:17.642594800Z",
     "start_time": "2023-12-13T22:43:17.457037200Z"
    }
   },
   "id": "ac70d5823dcf9c57"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "mask = nib.load('real_data/mask.nii').get_fdata().astype(bool)\n",
    "white_mask = nib.load('real_data/white_matter_mask.nii').get_fdata().astype(bool)\n",
    "\n",
    "hardi_snr10 = nib.load('real_data/DWIS_hardi-scheme_SNR-10.nii').get_fdata()\n",
    "hardi_snr20 = nib.load('real_data/DWIS_hardi-scheme_SNR-20.nii').get_fdata()\n",
    "hardi_snr30 = nib.load('real_data/DWIS_hardi-scheme_SNR-30.nii').get_fdata()\n",
    "\n",
    "hardi_snr10_masked = hardi_snr10[mask]\n",
    "hardi_snr20_masked = hardi_snr20[mask]\n",
    "hardi_snr30_masked = hardi_snr30[mask]\n",
    "hardi_snr10_masked *= (100/hardi_snr10_masked[0][0])\n",
    "hardi_snr20_masked *= (100/hardi_snr20_masked[0][0])\n",
    "hardi_snr30_masked *= (100/hardi_snr30_masked[0][0])\n",
    "\n",
    "hardi_snr10_white_masked = hardi_snr10[white_mask]\n",
    "hardi_snr20_white_masked = hardi_snr20[white_mask]\n",
    "hardi_snr30_white_masked = hardi_snr30[white_mask]\n",
    "hardi_snr10_white_masked *= (100/hardi_snr10_white_masked[0][0])\n",
    "hardi_snr20_white_masked *= (100/hardi_snr20_white_masked[0][0])\n",
    "hardi_snr30_white_masked *= (100/hardi_snr30_white_masked[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:46:47.523635500Z",
     "start_time": "2023-12-13T22:46:47.159908400Z"
    }
   },
   "id": "e766195dd6b51b40"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_set_hardi = torch.from_numpy(hardi_snr30_white_masked).float()\n",
    "F_test_set_hardi = torch.from_numpy(np.zeros(hardi_snr30_white_masked.shape[0])).float()\n",
    "test_dataset_hardi = MatrixDataset(test_set_hardi, F_test_set_hardi)\n",
    "test_loader_hardi = DataLoader(test_dataset_hardi, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:46:47.540587900Z",
     "start_time": "2023-12-13T22:46:47.525749600Z"
    }
   },
   "id": "eafc512019f8e595"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    F_pred_matrix_normalized_list = []\n",
    "\n",
    "    for S_batch, F_batch in test_loader_hardi:\n",
    "        S_batch_flattened = S_batch.to_dense().view(S_batch.size(0), -1)\n",
    "\n",
    "        F_batch_pred = net(S_batch_flattened)\n",
    "        F_batch_pred = apply_sparsity(F_batch_pred)\n",
    "        F_batch_pred_normalized = F_batch_pred / F_batch_pred.sum(dim=1, keepdim=True)\n",
    "\n",
    "        #loss = criterion(F_batch_pred_normalized, F_batch)\n",
    "\n",
    "        #total_loss += loss.item()\n",
    "        F_pred_matrix_normalized_list.append(F_batch_pred_normalized)\n",
    "\n",
    "    # Calculate the average loss over all test samples\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(\"Average Test Loss:\", avg_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:46:52.026347900Z",
     "start_time": "2023-12-13T22:46:51.713131500Z"
    }
   },
   "id": "26ae2c6afe721f03"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "F_pred_np = np.concatenate([tensor.cpu().numpy().flatten() for tensor in F_pred_matrix_normalized_list])\n",
    "F_pred_np = F_pred_np.reshape((-1,180)).astype(np.double)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:46:55.147710100Z",
     "start_time": "2023-12-13T22:46:55.089988Z"
    }
   },
   "id": "45070b069920ae3b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[ 61  62  64  63  57  58  60  59 132 179]\n",
      "[0. 0. 1.]\n",
      "[ 60 179 132]\n"
     ]
    }
   ],
   "source": [
    "indices_top10 = np.argpartition(F_pred_np[0], -10)[-10:]\n",
    "\n",
    "# Get the top 10 largest elements\n",
    "print(F_pred_np[0][indices_top10])\n",
    "print(indices_top10)\n",
    "\n",
    "indices_top3_true = np.argpartition(F_test[0], -3)[-3:]\n",
    "# Get the top 3 largest elements\n",
    "print(F_test[0][indices_top3_true])\n",
    "print(indices_top3_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:27.727967300Z",
     "start_time": "2023-12-13T22:43:27.690516900Z"
    }
   },
   "id": "aa803815b91516db"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "relative_peak_threshold = 0.1\n",
    "min_separation_angle = 25\n",
    "\n",
    "peak_format, peak_count = detect_peaks(F_pred_np, relative_peak_threshold, min_separation_angle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:47:10.862803200Z",
     "start_time": "2023-12-13T22:47:09.593203200Z"
    }
   },
   "id": "c237a066b735020a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.30097467, 0.05795585, 0.06995984, ..., 0.        , 0.        ,\n        0.        ],\n       [0.22633837, 0.22264666, 0.24471267, ..., 0.        , 0.        ,\n        0.        ],\n       [0.01152044, 0.02600314, 0.20201097, ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.2099885 , 0.20656347, 0.22703551, ..., 0.        , 0.        ,\n        0.        ],\n       [0.17811752, 0.17521232, 0.19257722, ..., 0.        , 0.        ,\n        0.        ],\n       [0.11972951, 0.11777665, 0.12944923, ..., 0.        , 0.        ,\n        0.        ]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:47:11.240145800Z",
     "start_time": "2023-12-13T22:47:11.209738400Z"
    }
   },
   "id": "c6a0438cbf259004"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "11.0"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:47:17.939308400Z",
     "start_time": "2023-12-13T22:47:17.874813900Z"
    }
   },
   "id": "3c1cd6245a6e7fb7"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pd.to_pickle(peak_format, \"trained.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:47:12.378895500Z",
     "start_time": "2023-12-13T22:47:12.307469300Z"
    }
   },
   "id": "d99c9599ff7193f4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "a = pd.read_pickle(\"synthetic_data/peaks_synthetic_formatted.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:49.784648800Z",
     "start_time": "2023-12-13T22:43:49.754338600Z"
    }
   },
   "id": "a24c0f805f8b815e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cutted_gt = a[train_len:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:51.059249700Z",
     "start_time": "2023-12-13T22:43:51.019849900Z"
    }
   },
   "id": "a8d507c1d8714601"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "pd.to_pickle(cutted_gt, 'gt_peaks_val_set.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T22:43:51.501234400Z",
     "start_time": "2023-12-13T22:43:51.454185500Z"
    }
   },
   "id": "36ee05b286e96189"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "97386f0621e95c1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
